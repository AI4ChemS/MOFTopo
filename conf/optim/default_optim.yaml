optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
  betas: [0.9, 0.999] 
  eps: 1e-08

use_lr_scheduler: True
lr_scheduler:
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    factor: 0.6
    patience: 3
    min_lr: 1e-5

  lr_monitor: ${logging.labels.train_loss_label}
