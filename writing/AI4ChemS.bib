@online{14VariationalAutoencoder,
  title = {14. {{Variational Autoencoder}} — Deep Learning for Molecules \& Materials},
  url = {https://dmol.pub/dl/VAE.html},
  urldate = {2024-05-06},
  abstract = {Deep Learning for Molecules \& Materials Book},
  file = {/Users/joshgoldman/Zotero/storage/2TVHCHUN/VAE.html}
}

@article{batznerEquivariantGraphNeural2022,
  title = {E(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials},
  author = {Batzner, Simon and Musaelian, Albert and Sun, Lixin and Geiger, Mario and Mailoa, Jonathan P. and Kornbluth, Mordechai and Molinari, Nicola and Smidt, Tess E. and Kozinsky, Boris},
  date = {2022-05-04},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {2453},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-29939-5},
  url = {https://www.nature.com/articles/s41467-022-29939-5},
  urldate = {2024-06-06},
  abstract = {This work presents Neural Equivariant Interatomic Potentials (NequIP), an E(3)-equivariant neural network approach for learning interatomic potentials from ab-initio calculations for molecular dynamics simulations. While most contemporary symmetry-aware models use invariant convolutions and only act on scalars, NequIP employs E(3)-equivariant convolutions for interactions of geometric tensors, resulting in a more information-rich and faithful representation of atomic environments. The method achieves state-of-the-art accuracy on a challenging and diverse set of molecules and materials while exhibiting remarkable data efficiency. NequIP outperforms existing models with up to three orders of magnitude fewer training data, challenging the widely held belief that deep neural networks require massive training sets. The high data efficiency of the method allows for the construction of accurate potentials using high-order quantum chemical level of theory as reference and enables high-fidelity molecular dynamics simulations over long time scales.},
  langid = {english},
  keywords = {Atomistic models,Computational chemistry,Computational methods,Computer science,Molecular dynamics},
  file = {/Users/joshgoldman/Zotero/storage/VUZ2E6NS/Batzner et al. - 2022 - E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials.pdf}
}

@article{boydComputationalDevelopmentNanoporous2017,
  title = {Computational Development of the Nanoporous Materials Genome},
  author = {Boyd, Peter G. and Lee, Yongjin and Smit, Berend},
  date = {2017-07-04},
  journaltitle = {Nature Reviews Materials},
  shortjournal = {Nat Rev Mater},
  volume = {2},
  number = {8},
  pages = {1--15},
  publisher = {Nature Publishing Group},
  issn = {2058-8437},
  doi = {10.1038/natrevmats.2017.37},
  url = {https://www.nature.com/articles/natrevmats201737},
  urldate = {2024-05-09},
  abstract = {There is currently a push towards big data and data mining in materials research to accelerate discovery. Zeolites, metal–organic frameworks and other related crystalline porous materials are not immune to this phenomenon, as evidenced by the proliferation of porous structure databases and computational gas-adsorption screening studies over the past decade. The endeavour to identify the best materials for various gas separation and storage applications has led not only to thousands of synthesized structures, but also to the development of algorithms for building hypothetical materials. The materials databases assembled with these algorithms contain a much wider range of complex pore structures than have been synthesized, with the reasoning being that we have discovered only a small fraction of realizable structures and expanding upon these will accelerate rational design. In this Review, we highlight the methods developed to build these databases, and some of the important outcomes from large-scale computational screening studies.},
  langid = {english},
  keywords = {Computational methods,Metal–organic frameworks,Organic–inorganic nanostructures,Porous materials},
  file = {/Users/joshgoldman/Zotero/storage/CSVIRDM9/Boyd et al. - 2017 - Computational development of the nanoporous materials genome.pdf}
}

@article{buciorIdentificationSchemesMetal2019,
  title = {Identification {{Schemes}} for {{Metal}}–{{Organic Frameworks To Enable Rapid Search}} and {{Cheminformatics Analysis}}},
  author = {Bucior, Benjamin J. and Rosen, Andrew S. and Haranczyk, Maciej and Yao, Zhenpeng and Ziebel, Michael E. and Farha, Omar K. and Hupp, Joseph T. and Siepmann, J. Ilja and Aspuru-Guzik, Alán and Snurr, Randall Q.},
  date = {2019-11-06},
  journaltitle = {Crystal Growth \& Design},
  shortjournal = {Crystal Growth \& Design},
  volume = {19},
  number = {11},
  pages = {6682--6697},
  publisher = {American Chemical Society},
  issn = {1528-7483},
  doi = {10.1021/acs.cgd.9b01050},
  url = {https://doi.org/10.1021/acs.cgd.9b01050},
  urldate = {2024-05-07},
  abstract = {The modular nature of metal–organic frameworks (MOFs) leads to a very large number of possible structures. High-throughput computational screening has led to a rapid increase in property data that has enabled several potential applications for MOFs, including gas storage, separations, catalysis, and other fields. Despite their rich chemistry, MOFs are typically named using an ad hoc approach, which can impede their searchability and the discovery of broad insights. In this article, we develop two systematic MOF identifiers, coined MOFid and MOFkey, and algorithms for deconstructing MOFs into their building blocks and underlying topological network. We review existing cheminformatics formats for small molecules and address the challenges of adapting them to periodic crystal structures. Our algorithms are distributed as open-source software, and we apply them here to extract insights from several MOF databases. Through the process of designing MOFid and MOFkey, we provide a perspective on opportunities for the community to facilitate data reuse, improve searchability, and rapidly apply cheminformatics analyses.},
  file = {/Users/joshgoldman/Zotero/storage/5ANXXIT5/Bucior et al. - 2019 - Identification Schemes for Metal–Organic Frameworks To Enable Rapid Search and Cheminformatics Analy.pdf}
}

@article{buciorIdentificationSchemesMetal2019a,
  title = {Identification {{Schemes}} for {{Metal}}–{{Organic Frameworks To Enable Rapid Search}} and {{Cheminformatics Analysis}}},
  author = {Bucior, Benjamin J. and Rosen, Andrew S. and Haranczyk, Maciej and Yao, Zhenpeng and Ziebel, Michael E. and Farha, Omar K. and Hupp, Joseph T. and Siepmann, J. Ilja and Aspuru-Guzik, Alán and Snurr, Randall Q.},
  date = {2019-11-06},
  journaltitle = {Crystal Growth \& Design},
  shortjournal = {Crystal Growth \& Design},
  volume = {19},
  number = {11},
  pages = {6682--6697},
  publisher = {American Chemical Society},
  issn = {1528-7483},
  doi = {10.1021/acs.cgd.9b01050},
  url = {https://doi.org/10.1021/acs.cgd.9b01050},
  urldate = {2024-05-10},
  abstract = {The modular nature of metal–organic frameworks (MOFs) leads to a very large number of possible structures. High-throughput computational screening has led to a rapid increase in property data that has enabled several potential applications for MOFs, including gas storage, separations, catalysis, and other fields. Despite their rich chemistry, MOFs are typically named using an ad hoc approach, which can impede their searchability and the discovery of broad insights. In this article, we develop two systematic MOF identifiers, coined MOFid and MOFkey, and algorithms for deconstructing MOFs into their building blocks and underlying topological network. We review existing cheminformatics formats for small molecules and address the challenges of adapting them to periodic crystal structures. Our algorithms are distributed as open-source software, and we apply them here to extract insights from several MOF databases. Through the process of designing MOFid and MOFkey, we provide a perspective on opportunities for the community to facilitate data reuse, improve searchability, and rapidly apply cheminformatics analyses.},
  file = {/Users/joshgoldman/Zotero/storage/VEZY39BD/Bucior et al. - 2019 - Identification Schemes for Metal–Organic Frameworks To Enable Rapid Search and Cheminformatics Analy.pdf}
}

@article{caoMOFormerSelfSupervisedTransformer2023,
  title = {{{MOFormer}}: {{Self-Supervised Transformer Model}} for {{Metal}}–{{Organic Framework Property Prediction}}},
  shorttitle = {{{MOFormer}}},
  author = {Cao, Zhonglin and Magar, Rishikesh and Wang, Yuyang and Barati Farimani, Amir},
  date = {2023-02-08},
  journaltitle = {Journal of the American Chemical Society},
  shortjournal = {J. Am. Chem. Soc.},
  volume = {145},
  number = {5},
  pages = {2958--2967},
  publisher = {American Chemical Society},
  issn = {0002-7863},
  doi = {10.1021/jacs.2c11420},
  url = {https://doi.org/10.1021/jacs.2c11420},
  urldate = {2024-05-08},
  abstract = {Metal–organic frameworks (MOFs) are materials with a high degree of porosity that can be used for many applications. However, the chemical space of MOFs is enormous due to the large variety of possible combinations of building blocks and topology. Discovering the optimal MOFs for specific applications requires an efficient and accurate search over countless potential candidates. Previous high-throughput screening methods using computational simulations like DFT can be time-consuming. Such methods also require the 3D atomic structures of MOFs, which adds one extra step when evaluating hypothetical MOFs. In this work, we propose a structure-agnostic deep learning method based on the Transformer model, named as MOFormer, for property predictions of MOFs. MOFormer takes a text string representation of MOF (MOFid) as input, thus circumventing the need of obtaining the 3D structure of a hypothetical MOF and accelerating the screening process. By comparing to other descriptors such as Stoichiometric-120 and revised autocorrelations, we demonstrate that MOFormer can achieve state-of-the-art structure-agnostic prediction accuracy on all benchmarks. Furthermore, we introduce a self-supervised learning framework that pretrains the MOFormer via maximizing the cross-correlation between its structure-agnostic representations and structure-based representations of the crystal graph convolutional neural network (CGCNN) on {$>$}400k publicly available MOF data. Benchmarks show that pretraining improves the prediction accuracy of both models on various downstream prediction tasks. Furthermore, we revealed that MOFormer can be more data-efficient on quantum-chemical property prediction than structure-based CGCNN when training data is limited. Overall, MOFormer provides a novel perspective on efficient MOF property prediction using deep learning.},
  file = {/Users/joshgoldman/Zotero/storage/T55GIPRY/Supplemental Information.pdf;/Users/joshgoldman/Zotero/storage/TPKED96N/Cao et al. - 2023 - MOFormer Self-Supervised Transformer Model for Metal–Organic Framework Property Prediction.pdf}
}

@article{caoSurveyGenerativeDiffusion2024,
  title = {A {{Survey}} on {{Generative Diffusion Models}}},
  author = {Cao, Hanqun and Tan, Cheng and Gao, Zhangyang and Xu, Yilun and Chen, Guangyong and Heng, Pheng-Ann and Li, Stan Z.},
  date = {2024},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  pages = {1--20},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2024.3361474},
  url = {https://ieeexplore.ieee.org/abstract/document/10419041?casa_token=GcG1VwrVSO8AAAAA:vpumOQ3cRq_8bS9DtL4VS3VKQtbR4N0R-D_G6GsbA_FDbixVghJb1fyk4VS-Btgw8JFMA2EXoBo},
  urldate = {2024-05-06},
  abstract = {Deep generative models have unlocked another profound realm of human creativity. By capturing and generalizing patterns within data, we have entered the epoch of all-encompassing Artificial Intelligence for General Creativity (AIGC). Notably, diffusion models, recognized as one of the paramount generative models, materialize human ideation into tangible instances across diverse domains, encompassing imagery, text, speech, biology, and healthcare. To provide advanced and comprehensive insights into diffusion, this survey comprehensively elucidates its developmental trajectory and future directions from three distinct angles: the fundamental formulation of diffusion, algorithmic enhancements, and the manifold applications of diffusion. Each layer is meticulously explored to offer a profound comprehension of its evolution. Structured and summarized approaches are presented here.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  keywords = {Computational modeling,Deep Generative Model,Diffusion Algorithm,Diffusion Applications,Diffusion Model,Kernel,Markov processes,Mathematical models,Noise reduction,Surveys,Training},
  file = {/Users/joshgoldman/Zotero/storage/CDFDQUT6/10419041.html}
}

@article{carleoSolvingQuantumManybody2017,
  title = {Solving the Quantum Many-Body Problem with Artificial Neural Networks},
  author = {Carleo, Giuseppe and Troyer, Matthias},
  date = {2017-02-10},
  journaltitle = {Science},
  volume = {355},
  number = {6325},
  pages = {602--606},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aag2302},
  url = {https://www.science.org/doi/full/10.1126/science.aag2302},
  urldate = {2024-05-09},
  abstract = {The challenge posed by the many-body problem in quantum physics originates from the difficulty of describing the nontrivial correlations encoded in the exponential complexity of the many-body wave function. Here we demonstrate that systematic machine learning of the wave function can reduce this complexity to a tractable computational form for some notable cases of physical interest. We introduce a variational representation of quantum states based on artificial neural networks with a variable number of hidden neurons. A reinforcement-learning scheme we demonstrate is capable of both finding the ground state and describing the unitary time evolution of complex interacting quantum systems. Our approach achieves high accuracy in describing prototypical interacting spins models in one and two dimensions.},
  file = {/Users/joshgoldman/Zotero/storage/TZI3HZG9/Carleo and Troyer - 2017 - Solving the quantum many-body problem with artificial neural networks.pdf}
}

@inproceedings{choiCycleCliqueCy2C2022,
  title = {Cycle to {{Clique}} ({{Cy2C}}) {{Graph Neural Network}}: {{A Sight}} to {{See}} beyond {{Neighborhood Aggregation}}},
  shorttitle = {Cycle to {{Clique}} ({{Cy2C}}) {{Graph Neural Network}}},
  author = {Choi, Yun Young and Park, Sun Woo and Woo, Youngho and Choi, U. Jin},
  date = {2022-09-29},
  url = {https://openreview.net/forum?id=7d-g8KozkiE},
  urldate = {2024-06-10},
  abstract = {Graph neural networks have been successfully adapted for learning vector representations of graphs through various neighborhood aggregation schemes. Previous researches suggest, however, that they possess limitations in incorporating key non-Euclidean topological properties of graphs. This paper mathematically identifies the caliber of graph neural networks in classifying isomorphism classes of graphs with continuous node attributes up to their local topological properties. In light of these observations, we construct the Cycle to Clique graph neural network, a novel yet simple algorithm which topologically enriches the input data of conventional graph neural networks while preserving their architectural components. This method theoretically outperforms conventional graph neural networks in classifying isomorphism classes of graphs while ensuring comparable time complexity in representing random graphs. Empirical results further support that the novel algorithm produces comparable or enhanced results in classifying benchmark graph data sets compared to contemporary variants of graph neural networks.},
  eventtitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/IUVHV9BT/Choi et al. - 2022 - Cycle to Clique (Cy2C) Graph Neural Network A Sight to See beyond Neighborhood Aggregation.pdf}
}

@online{doerschTutorialVariationalAutoencoders2021,
  title = {Tutorial on {{Variational Autoencoders}}},
  author = {Doersch, Carl},
  date = {2021-01-03},
  eprint = {1606.05908},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1606.05908},
  url = {http://arxiv.org/abs/1606.05908},
  urldate = {2024-05-06},
  abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/joshgoldman/Zotero/storage/W78UYBN8/Doersch - 2021 - Tutorial on Variational Autoencoders.pdf;/Users/joshgoldman/Zotero/storage/HLTUTXRB/1606.html}
}

@online{FlowbasedDeepGenerative,
  title = {Flow-Based {{Deep Generative Models}} | {{Lil}}'{{Log}}},
  url = {https://lilianweng.github.io/posts/2018-10-13-flow-models/},
  urldate = {2024-05-06},
  file = {/Users/joshgoldman/Zotero/storage/YEYB8F83/2018-10-13-flow-models.html}
}

@online{fuMOFDiffCoarsegrainedDiffusion2023,
  title = {{{MOFDiff}}: {{Coarse-grained Diffusion}} for {{Metal-Organic Framework Design}}},
  shorttitle = {{{MOFDiff}}},
  author = {Fu, Xiang and Xie, Tian and Rosen, Andrew S. and Jaakkola, Tommi and Smith, Jake},
  date = {2023-10-16},
  eprint = {2310.10732},
  eprinttype = {arxiv},
  eprintclass = {cond-mat, physics:physics},
  doi = {10.48550/arXiv.2310.10732},
  url = {http://arxiv.org/abs/2310.10732},
  urldate = {2024-05-08},
  abstract = {Metal-organic frameworks (MOFs) are of immense interest in applications such as gas storage and carbon capture due to their exceptional porosity and tunable chemistry. Their modular nature has enabled the use of template-based methods to generate hypothetical MOFs by combining molecular building blocks in accordance with known network topologies. However, the ability of these methods to identify top-performing MOFs is often hindered by the limited diversity of the resulting chemical space. In this work, we propose MOFDiff: a coarse-grained (CG) diffusion model that generates CG MOF structures through a denoising diffusion process over the coordinates and identities of the building blocks. The all-atom MOF structure is then determined through a novel assembly algorithm. Equivariant graph neural networks are used for the diffusion model to respect the permutational and roto-translational symmetries. We comprehensively evaluate our model's capability to generate valid and novel MOF structures and its effectiveness in designing outstanding MOF materials for carbon capture applications with molecular simulations.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Materials Science,Physics - Chemical Physics},
  file = {/Users/joshgoldman/Zotero/storage/EC4BTAZJ/Fu et al. - 2023 - MOFDiff Coarse-grained Diffusion for Metal-Organic Framework Design.pdf;/Users/joshgoldman/Zotero/storage/MNCGQ6MU/2310.html}
}

@online{gasteigerDirectionalMessagePassing2022,
  title = {Directional {{Message Passing}} for {{Molecular Graphs}}},
  author = {Gasteiger, Johannes and Groß, Janek and Günnemann, Stephan},
  date = {2022-04-05},
  eprint = {2003.03123},
  eprinttype = {arxiv},
  eprintclass = {physics, stat},
  doi = {10.48550/arXiv.2003.03123},
  url = {http://arxiv.org/abs/2003.03123},
  urldate = {2024-05-15},
  abstract = {Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes). They do not, however, consider the spatial direction from one atom to another, despite directional information playing a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions and spherical harmonics to construct theoretically well-founded, orthogonal representations that achieve better performance than the currently prevalent Gaussian radial basis representations while using fewer than 1/4 of the parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 76\% on MD17 and by 31\% on QM9. Our implementation is available online.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Physics - Computational Physics,Statistics - Machine Learning},
  file = {/Users/joshgoldman/Zotero/storage/TGLJRTS6/Gasteiger et al. - 2022 - Directional Message Passing for Molecular Graphs.pdf;/Users/joshgoldman/Zotero/storage/VZRTH4EU/2003.html}
}

@online{gasteigerFastUncertaintyAwareDirectional2022,
  title = {Fast and {{Uncertainty-Aware Directional Message Passing}} for {{Non-Equilibrium Molecules}}},
  author = {Gasteiger, Johannes and Giri, Shankari and Margraf, Johannes T. and Günnemann, Stephan},
  date = {2022-04-05},
  eprint = {2011.14115},
  eprinttype = {arxiv},
  eprintclass = {physics},
  doi = {10.48550/arXiv.2011.14115},
  url = {http://arxiv.org/abs/2011.14115},
  urldate = {2024-05-15},
  abstract = {Many important tasks in chemistry revolve around molecules during reactions. This requires predictions far from the equilibrium, while most recent work in machine learning for molecules has been focused on equilibrium or near-equilibrium states. In this paper we aim to extend this scope in three ways. First, we propose the DimeNet++ model, which is 8x faster and 10\% more accurate than the original DimeNet on the QM9 benchmark of equilibrium molecules. Second, we validate DimeNet++ on highly reactive molecules by developing the challenging COLL dataset, which contains distorted configurations of small molecules during collisions. Finally, we investigate ensembling and mean-variance estimation for uncertainty quantification with the goal of accelerating the exploration of the vast space of non-equilibrium structures. Our DimeNet++ implementation as well as the COLL dataset are available online.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Physics - Chemical Physics,Physics - Computational Physics},
  file = {/Users/joshgoldman/Zotero/storage/VWS47ZAZ/Gasteiger et al. - 2022 - Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules.pdf;/Users/joshgoldman/Zotero/storage/Y5TQ8U6Q/2011.html}
}

@inproceedings{gasteigerGemNetUniversalDirectional2021,
  title = {{{GemNet}}: {{Universal Directional Graph Neural Networks}} for {{Molecules}}},
  shorttitle = {{{GemNet}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Gasteiger, Johannes and Becker, Florian and Günnemann, Stephan},
  date = {2021},
  volume = {34},
  pages = {6790--6802},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/hash/35cf8659cfcb13224cbd47863a34fc58-Abstract.html},
  urldate = {2024-05-15},
  abstract = {Effectively predicting molecular interactions has the potential to accelerate molecular dynamics by multiple orders of magnitude and thus revolutionize chemical simulations. Graph neural networks (GNNs) have recently shown great successes for this task, overtaking classical methods based on fixed molecular kernels. However, they still appear very limited from a theoretical perspective, since regular GNNs cannot distinguish certain types of graphs. In this work we close this gap between theory and practice. We show that GNNs with directed edge embeddings and two-hop message passing are indeed universal approximators for predictions that are invariant to translation, and equivariant to permutation and rotation. We then leverage these insights and multiple structural improvements to propose the geometric message passing neural network (GemNet). We demonstrate the benefits of the proposed changes in multiple ablation studies. GemNet outperforms previous models on the COLL, MD17, and OC20 datasets by 34\%, 41\%, and 20\%, respectively, and performs especially well on the most challenging molecules. Our implementation is available online.},
  file = {/Users/joshgoldman/Zotero/storage/6TGIW8UB/Gasteiger et al. - 2021 - GemNet Universal Directional Graph Neural Networks for Molecules.pdf}
}

@online{GenerativeModelingEstimating,
  title = {Generative {{Modeling}} by {{Estimating Gradients}} of the {{Data Distribution}} | {{Yang Song}}},
  url = {https://yang-song.net/blog/2021/score/},
  urldate = {2024-05-08},
  file = {/Users/joshgoldman/Zotero/storage/8HPFZT2G/score.html}
}

@article{gerkenGeometricDeepLearning2023,
  title = {Geometric Deep Learning and Equivariant Neural Networks},
  author = {Gerken, Jan E. and Aronsson, Jimmy and Carlsson, Oscar and Linander, Hampus and Ohlsson, Fredrik and Petersson, Christoffer and Persson, Daniel},
  date = {2023-12-01},
  journaltitle = {Artificial Intelligence Review},
  shortjournal = {Artif Intell Rev},
  volume = {56},
  number = {12},
  pages = {14605--14662},
  issn = {1573-7462},
  doi = {10.1007/s10462-023-10502-7},
  url = {https://doi.org/10.1007/s10462-023-10502-7},
  urldate = {2024-05-06},
  abstract = {We survey the mathematical foundations of geometric deep learning, focusing on group equivariant and gauge equivariant neural networks. We develop gauge equivariant convolutional neural networks on arbitrary manifolds \$\$\textbackslash mathcal \{M\}\$\$using principal bundles with structure group K and equivariant maps between sections of associated vector bundles. We also discuss group equivariant neural networks for homogeneous spaces \$\$\textbackslash mathcal \{M\}=G/K\$\$, which are instead equivariant with respect to the global symmetry G on \$\$\textbackslash mathcal \{M\}\$\$. Group equivariant layers can be interpreted as intertwiners between induced representations of G, and we show their relation to gauge equivariant convolutional layers. We analyze several applications of this formalism, including semantic segmentation and object detection networks. We also discuss the case of spherical networks in great detail, corresponding to the case \$\$\textbackslash mathcal \{M\}=S\textasciicircum 2=\textbackslash textrm\{SO\}(3)/\textbackslash textrm\{SO\}(2)\$\$. Here we emphasize the use of Fourier analysis involving Wigner matrices, spherical harmonics and Clebsch–Gordan coefficients for \$\$G=\textbackslash textrm\{SO\}(3)\$\$, illustrating the power of representation theory for deep learning.},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/XB4YYXG2/Gerken et al. - 2023 - Geometric deep learning and equivariant neural networks.pdf}
}

@online{hajijTopologicalDeepLearning2023,
  title = {Topological {{Deep Learning}}: {{Going Beyond Graph Data}}},
  shorttitle = {Topological {{Deep Learning}}},
  author = {Hajij, Mustafa and Zamzmi, Ghada and Papamarkou, Theodore and Miolane, Nina and Guzmán-Sáenz, Aldo and Ramamurthy, Karthikeyan Natesan and Birdal, Tolga and Dey, Tamal K. and Mukherjee, Soham and Samaga, Shreyas N. and Livesay, Neal and Walters, Robin and Rosen, Paul and Schaub, Michael T.},
  date = {2023-05-19},
  eprint = {2206.00606},
  eprinttype = {arxiv},
  eprintclass = {cs, math, stat},
  doi = {10.48550/arXiv.2206.00606},
  url = {http://arxiv.org/abs/2206.00606},
  urldate = {2024-06-07},
  abstract = {Topological deep learning is a rapidly growing field that pertains to the development of deep learning models for data supported on topological domains such as simplicial complexes, cell complexes, and hypergraphs, which generalize many domains encountered in scientific computations. In this paper, we present a unifying deep learning framework built upon a richer data structure that includes widely adopted topological domains. Specifically, we first introduce combinatorial complexes, a novel type of topological domain. Combinatorial complexes can be seen as generalizations of graphs that maintain certain desirable properties. Similar to hypergraphs, combinatorial complexes impose no constraints on the set of relations. In addition, combinatorial complexes permit the construction of hierarchical higher-order relations, analogous to those found in simplicial and cell complexes. Thus, combinatorial complexes generalize and combine useful traits of both hypergraphs and cell complexes, which have emerged as two promising abstractions that facilitate the generalization of graph neural networks to topological spaces. Second, building upon combinatorial complexes and their rich combinatorial and algebraic structure, we develop a general class of message-passing combinatorial complex neural networks (CCNNs), focusing primarily on attention-based CCNNs. We characterize permutation and orientation equivariances of CCNNs, and discuss pooling and unpooling operations within CCNNs in detail. Third, we evaluate the performance of CCNNs on tasks related to mesh shape analysis and graph learning. Our experiments demonstrate that CCNNs have competitive performance as compared to state-of-the-art deep learning models specifically tailored to the same tasks. Our findings demonstrate the advantages of incorporating higher-order relations into deep learning models in different applications.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Mathematics - Algebraic Topology,Statistics - Machine Learning},
  file = {/Users/joshgoldman/Zotero/storage/AISFS57A/Hajij et al. - 2023 - Topological Deep Learning Going Beyond Graph Data.pdf;/Users/joshgoldman/Zotero/storage/G2TYF8ST/2206.html}
}

@inproceedings{hoogeboomEquivariantDiffusionMolecule2022,
  title = {Equivariant {{Diffusion}} for {{Molecule Generation}} in {{3D}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Hoogeboom, Emiel and Satorras, Vı́ctor Garcia and Vignac, Clément and Welling, Max},
  date = {2022-06-28},
  pages = {8867--8887},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v162/hoogeboom22a.html},
  urldate = {2024-05-06},
  abstract = {This work introduces a diffusion model for molecule generation in 3D that is equivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model (EDM) learns to denoise a diffusion process with an equivariant network that jointly operates on both continuous (atom coordinates) and categorical features (atom types). In addition, we provide a probabilistic analysis which admits likelihood computation of molecules using our model. Experimentally, the proposed method significantly outperforms previous 3D molecular generative methods regarding the quality of generated samples and the efficiency at training time.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/WFPEJCJU/Hoogeboom et al. - 2022 - Equivariant Diffusion for Molecule Generation in 3D.pdf}
}

@inproceedings{houGraphMAESelfSupervisedMasked2022,
  title = {{{GraphMAE}}: {{Self-Supervised Masked Graph Autoencoders}}},
  shorttitle = {{{GraphMAE}}},
  booktitle = {Proceedings of the 28th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Hou, Zhenyu and Liu, Xiao and Cen, Yukuo and Dong, Yuxiao and Yang, Hongxia and Wang, Chunjie and Tang, Jie},
  date = {2022-08-14},
  series = {{{KDD}} '22},
  pages = {594--604},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3534678.3539321},
  url = {https://dl.acm.org/doi/10.1145/3534678.3539321},
  urldate = {2024-06-07},
  abstract = {Self-supervised learning (SSL) has been extensively explored in recent years. Particularly, generative SSL has seen emerging success in natural language processing and other fields, such as the wide adoption of BERT and GPT. Despite this, contrastive learning---which heavily relies on structural data augmentation and complicated training strategies---has been the dominant approach in graph SSL, while the progress of generative SSL on graphs, especially graph autoencoders (GAEs), has thus far not reached the potential as promised in other fields. In this paper, we identify and examine the issues that negatively impact the development of GAEs, including their reconstruction objective, training robustness, and error metric. We present a masked graph autoencoder GraphMAE (code is publicly available at https://github.com/THUDM/GraphMAE) that mitigates these issues for generative self-supervised graph learning. Instead of reconstructing structures, we propose to focus on feature reconstruction with both a masking strategy and scaled cosine error that benefit the robust training of GraphMAE. We conduct extensive experiments on 21 public datasets for three different graph learning tasks. The results manifest that GraphMAE---a simple graph autoencoder with our careful designs---can consistently generate outperformance over both contrastive and generative state-of-the-art baselines. This study provides an understanding of graph autoencoders and demonstrates the potential of generative self-supervised learning on graphs.},
  isbn = {978-1-4503-9385-0},
  keywords = {graph neural networks,graph representation learning,self-supervised learning},
  file = {/Users/joshgoldman/Zotero/storage/JC336HMI/Hou et al. - 2022 - GraphMAE Self-Supervised Masked Graph Autoencoders.pdf}
}

@article{jablonkaBigDataSciencePorous2020,
  title = {Big-{{Data Science}} in {{Porous Materials}}: {{Materials Genomics}} and {{Machine Learning}}},
  shorttitle = {Big-{{Data Science}} in {{Porous Materials}}},
  author = {Jablonka, Kevin Maik and Ongari, Daniele and Moosavi, Seyed Mohamad and Smit, Berend},
  date = {2020-08-26},
  journaltitle = {Chemical Reviews},
  shortjournal = {Chem. Rev.},
  volume = {120},
  number = {16},
  pages = {8066--8129},
  publisher = {American Chemical Society},
  issn = {0009-2665},
  doi = {10.1021/acs.chemrev.0c00004},
  url = {https://doi.org/10.1021/acs.chemrev.0c00004},
  urldate = {2024-05-07},
  abstract = {By combining metal nodes with organic linkers we can potentially synthesize millions of possible metal–organic frameworks (MOFs). The fact that we have so many materials opens many exciting avenues but also create new challenges. We simply have too many materials to be processed using conventional, brute force, methods. In this review, we show that having so many materials allows us to use big-data methods as a powerful technique to study these materials and to discover complex correlations. The first part of the review gives an introduction to the principles of big-data science. We show how to select appropriate training sets, survey approaches that are used to represent these materials in feature space, and review different learning architectures, as well as evaluation and interpretation strategies. In the second part, we review how the different approaches of machine learning have been applied to porous materials. In particular, we discuss applications in the field of gas storage and separation, the stability of these materials, their electronic properties, and their synthesis. Given the increasing interest of the scientific community in machine learning, we expect this list to rapidly expand in the coming years.},
  file = {/Users/joshgoldman/Zotero/storage/6I7TTZ78/Jablonka et al. - 2020 - Big-Data Science in Porous Materials Materials Genomics and Machine Learning.pdf}
}

@article{jiaoCrystalStructurePrediction2023,
  title = {Crystal {{Structure Prediction}} by {{Joint Equivariant Diffusion}}},
  author = {Jiao, Rui and Huang, Wenbing and Lin, Peijia and Han, Jiaqi and Chen, Pin and Lu, Yutong and Liu, Yang},
  date = {2023-12-15},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {17464--17497},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/38b787fc530d0b31825827e2cc306656-Abstract-Conference.html},
  urldate = {2024-05-06},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/DVYGBMPX/Jiao et al. - 2023 - Crystal Structure Prediction by Joint Equivariant Diffusion.pdf}
}

@article{juComprehensiveSurveyDeep2024,
  title = {A {{Comprehensive Survey}} on {{Deep Graph Representation Learning}}},
  author = {Ju, Wei and Fang, Zheng and Gu, Yiyang and Liu, Zequn and Long, Qingqing and Qiao, Ziyue and Qin, Yifang and Shen, Jianhao and Sun, Fang and Xiao, Zhiping and Yang, Junwei and Yuan, Jingyang and Zhao, Yusheng and Wang, Yifan and Luo, Xiao and Zhang, Ming},
  date = {2024-05-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {173},
  pages = {106207},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2024.106207},
  url = {https://www.sciencedirect.com/science/article/pii/S089360802400131X},
  urldate = {2024-06-07},
  abstract = {Graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. Classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. However, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. With the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages over shallow (traditional) methods, there exist a large number of deep graph representation learning techniques have been proposed in the past decade, especially graph neural networks. In this survey, we conduct a comprehensive survey on current deep graph representation learning algorithms by proposing a new taxonomy of existing state-of-the-art literature. Specifically, we systematically summarize the essential components of graph representation learning and categorize existing approaches by the ways of graph neural network architectures and the most recent advanced learning paradigms. Moreover, this survey also provides the practical and promising applications of deep graph representation learning. Last but not least, we state new perspectives and suggest challenging directions which deserve further investigations in the future.},
  keywords = {Deep learning on graphs,Graph neural network,Graph representation learning,Survey},
  file = {/Users/joshgoldman/Zotero/storage/M6JPTNFN/Ju et al. - 2024 - A Comprehensive Survey on Deep Graph Representation Learning.pdf}
}

@book{kantorovichQuantumTheorySolid2004,
  title = {Quantum {{Theory}} of the {{Solid State}}: {{An Introduction}}},
  shorttitle = {Quantum {{Theory}} of the {{Solid State}}},
  author = {Kantorovich, Lev},
  date = {2004},
  publisher = {Springer Netherlands},
  location = {Dordrecht},
  doi = {10.1007/978-1-4020-2154-1},
  url = {http://link.springer.com/10.1007/978-1-4020-2154-1},
  urldate = {2024-05-14},
  isbn = {978-1-4020-2153-4 978-1-4020-2154-1},
  langid = {english},
  keywords = {crystal,diffraction,materials science,Potential,X-Ray},
  file = {/Users/joshgoldman/Zotero/storage/S8Y4TYFI/Kantorovich - 2004 - Quantum Theory of the Solid State An Introduction.pdf}
}

@incollection{karimiChapterMetalOrganic2021,
  title = {Chapter 4 - {{Metal}}–Organic Framework},
  booktitle = {Interface {{Science}} and {{Technology}}},
  author = {Karimi, Mehdi and Mehrabadi, Zohreh and Farsadrooh, Majid and Bafkary, Reza and Derikvandi, Hadis and Hayati, Payam and Mohammadi, Khosro},
  editor = {Ghaedi, Mehrorang},
  date = {2021-01-01},
  series = {Adsorption: {{Fundamental Processes}} and {{Applications}}},
  volume = {33},
  pages = {279--387},
  publisher = {Elsevier},
  doi = {10.1016/B978-0-12-818805-7.00010-2},
  url = {https://www.sciencedirect.com/science/article/pii/B9780128188057000102},
  urldate = {2024-05-07},
  abstract = {Metal–organic frameworks (MOFs) are fabricated by linking inorganic and organic units by strong bonds (reticular synthesis). The flexibleness with that the constituents, geometry, size, and functionality could be varied has resulted to more than 20,000 different MOFs being reported and studied within the past decade. At the start of the chapter a brief overview, kinds of ligands and various methods for synthesis of MOFs are described. The unique feature of MOFs led to a crucial issue to many applications in which MOFs are promising candidates. Multiphoton absorption, shockwave chemistry, electronic and vibrational properties of MOFs, novel PVA/MOF nanofibers, synthesis of amine-functionalized MOFs discussed here.},
  keywords = {Catalyst,Chemical sensor,MOF,Multiphoton absorption,Shockwave chemistry},
  file = {/Users/joshgoldman/Zotero/storage/5J8VSINB/Karimi et al. - 2021 - Chapter 4 - Metal–organic framework.pdf;/Users/joshgoldman/Zotero/storage/G3S5534I/B9780128188057000102.html}
}

@article{karsakovPredictionMetalOrganic2024,
  title = {Prediction of {{Metal}}–{{Organic Frameworks}} with {{Phase Transition}} via {{Machine Learning}}},
  author = {Karsakov, Grigory V. and Shirobokov, Vladimir P. and Kulakova, Alena and Milichko, Valentin A.},
  date = {2024-03-21},
  journaltitle = {The Journal of Physical Chemistry Letters},
  shortjournal = {J. Phys. Chem. Lett.},
  volume = {15},
  number = {11},
  pages = {3089--3095},
  publisher = {American Chemical Society},
  doi = {10.1021/acs.jpclett.3c03639},
  url = {https://doi.org/10.1021/acs.jpclett.3c03639},
  urldate = {2024-05-07},
  abstract = {Metal–organic frameworks (MOFs) possess a virtually unlimited number of potential structures. Although the latter enables an efficient route to control the structure-related functional properties of MOFs, it still complicates the prediction and searching for an optimal structure for specific application. Next to prediction of the MOFs for gas sorption/separation and catalysis via machine learning (ML), we report on ML to find MOFs demonstrating a phase transition (PT). On the basis of an available QMOF database (7463 frameworks), we create and train the autoencoder followed by training the classifier of MOFs from a unique database with experimentally confirmed PT. This makes it possible to identify MOFs with a high potential for PT and evaluate the most likely stimulus for it (guest molecules or temperature/pressure). The formed list of available MOFs for PT allows us to discuss their structural features and opens an opportunity to search for phase change MOFs for diverse physical/chemical application.},
  file = {/Users/joshgoldman/Zotero/storage/JGFMZJ7F/Karsakov et al. - 2024 - Prediction of Metal–Organic Frameworks with Phase Transition via Machine Learning.pdf}
}

@article{kingmaIntroductionVariationalAutoencoders2019,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2019},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {12},
  number = {4},
  eprint = {1906.02691},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {307--392},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  url = {http://arxiv.org/abs/1906.02691},
  urldate = {2024-05-06},
  abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/joshgoldman/Zotero/storage/ITMXHUIH/Kingma and Welling - 2019 - An Introduction to Variational Autoencoders.pdf;/Users/joshgoldman/Zotero/storage/WW7FK3CV/1906.html}
}

@online{kipfVariationalGraphAutoEncoders2016,
  title = {Variational {{Graph Auto-Encoders}}},
  author = {Kipf, Thomas N. and Welling, Max},
  date = {2016-11-21},
  url = {https://arxiv.org/abs/1611.07308v1},
  urldate = {2024-05-10},
  abstract = {We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.},
  langid = {english},
  organization = {arXiv.org},
  file = {/Users/joshgoldman/Zotero/storage/UM79UGJU/Kipf and Welling - 2016 - Variational Graph Auto-Encoders.pdf}
}

@software{klicperaGasteigerjoDimenet2024,
  title = {Gasteigerjo/Dimenet},
  author = {Klicpera, né, Johannes Gasteiger},
  date = {2024-05-07T12:26:32Z},
  origdate = {2020-02-14T12:40:15Z},
  url = {https://github.com/gasteigerjo/dimenet},
  urldate = {2024-05-15},
  abstract = {DimeNet and DimeNet++ models, as proposed in "Directional Message Passing for Molecular Graphs" (ICLR 2020) and "Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules" (NeurIPS-W 2020)},
  keywords = {architecture,paper,pretrained-models}
}

@article{krennSELFIESFutureMolecular2022,
  title = {{{SELFIES}} and the Future of Molecular String Representations},
  author = {Krenn, Mario and Ai, Qianxiang and Barthel, Senja and Carson, Nessa and Frei, Angelo and Frey, Nathan C. and Friederich, Pascal and Gaudin, Théophile and Gayle, Alberto Alexander and Jablonka, Kevin Maik and Lameiro, Rafael F. and Lemm, Dominik and Lo, Alston and Moosavi, Seyed Mohamad and Nápoles-Duarte, José Manuel and Nigam, AkshatKumar and Pollice, Robert and Rajan, Kohulan and Schatzschneider, Ulrich and Schwaller, Philippe and Skreta, Marta and Smit, Berend and Strieth-Kalthoff, Felix and Sun, Chong and Tom, Gary and Falk von Rudorff, Guido and Wang, Andrew and White, Andrew D. and Young, Adamo and Yu, Rose and Aspuru-Guzik, Alán},
  date = {2022-10-14},
  journaltitle = {Patterns},
  shortjournal = {Patterns},
  volume = {3},
  number = {10},
  pages = {100588},
  issn = {2666-3899},
  doi = {10.1016/j.patter.2022.100588},
  url = {https://www.sciencedirect.com/science/article/pii/S2666389922002069},
  urldate = {2024-06-10},
  abstract = {Artificial intelligence (AI) and machine learning (ML) are expanding in popularity for broad applications to challenging tasks in chemistry and materials science. Examples include the prediction of properties, the discovery of new reaction pathways, or the design of new molecules. The machine needs to read and write fluently in a chemical language for each of these tasks. Strings are a common tool to represent molecular graphs, and the most popular molecular string representation, Smiles, has powered cheminformatics since the late 1980s. However, in the context of AI and ML in chemistry, Smiles has several shortcomings—most pertinently, most combinations of symbols lead to invalid results with no valid chemical interpretation. To overcome this issue, a new language for molecules was introduced in 2020 that guarantees 100\% robustness: SELF-referencing embedded string (Selfies). Selfies has since simplified and enabled numerous new applications in chemistry. In this perspective, we look to the future and discuss molecular string representations, along with their respective opportunities and challenges. We propose 16 concrete future projects for robust molecular representations. These involve the extension toward new chemical domains, exciting questions at the interface of AI and robust languages, and interpretability for both humans and machines. We hope that these proposals will inspire several follow-up works exploiting the full potential of molecular string representations for the future of AI in chemistry and materials science.},
  file = {/Users/joshgoldman/Zotero/storage/TMBGMK6Q/Krenn et al. - 2022 - SELFIES and the future of molecular string representations.pdf;/Users/joshgoldman/Zotero/storage/8B3CPTZR/S2666389922002069.html}
}

@article{leeComputationalScreeningTrillions2021,
  title = {Computational {{Screening}} of {{Trillions}} of {{Metal}}–{{Organic Frameworks}} for {{High-Performance Methane Storage}}},
  author = {Lee, Sangwon and Kim, Baekjun and Cho, Hyun and Lee, Hooseung and Lee, Sarah Yunmi and Cho, Eun Seon and Kim, Jihan},
  date = {2021-05-26},
  journaltitle = {ACS Applied Materials \& Interfaces},
  shortjournal = {ACS Appl. Mater. Interfaces},
  volume = {13},
  number = {20},
  pages = {23647--23654},
  publisher = {American Chemical Society},
  issn = {1944-8244},
  doi = {10.1021/acsami.1c02471},
  url = {https://doi.org/10.1021/acsami.1c02471},
  urldate = {2024-05-09},
  abstract = {In the past decade, there has been an increasing number of computational screening works to facilitate finding optimal materials for a variety of different applications. Unfortunately, most of these screening studies are limited to their initial set of materials and result in a brute-force type of screening approach. In this work, we present a systematic strategy that can find metal–organic frameworks (MOFs) with the desired properties from an extremely diverse and large set of over 100 trillion possible MOFs using machine learning and evolutionary algorithm. It is demonstrated that our algorithm can discover 964 MOFs with methane working capacity over 200 cm3 cm–3 and 96 MOFs with methane working capacity over the current world record of 208 cm3 cm–3. We believe that this methodology can take advantage of the modular nature of MOFs and can readily be extended to other important applications as well.},
  file = {/Users/joshgoldman/Zotero/storage/BTRPGMK3/Lee et al. - 2021 - Computational Screening of Trillions of Metal–Organic Frameworks for High-Performance Methane Storag.pdf}
}

@article{leemanChallengesHighThroughputInorganic2024,
  title = {Challenges in {{High-Throughput Inorganic Materials Prediction}} and {{Autonomous Synthesis}}},
  author = {Leeman, Josh and Liu, Yuhan and Stiles, Joseph and Lee, Scott B. and Bhatt, Prajna and Schoop, Leslie M. and Palgrave, Robert G.},
  date = {2024-03-07},
  journaltitle = {PRX Energy},
  shortjournal = {PRX Energy},
  volume = {3},
  number = {1},
  pages = {011002},
  publisher = {American Physical Society},
  doi = {10.1103/PRXEnergy.3.011002},
  url = {https://link.aps.org/doi/10.1103/PRXEnergy.3.011002},
  urldate = {2024-05-09},
  abstract = {Materials discovery lays the foundation for many technological advancements. The prediction and discovery of new materials are not simple tasks. Here, we outline some basic principles of solid-state chemistry, which might help to advance both, and discuss pitfalls and challenges in materials discovery. Using the recent work of Szymanski et al. [Nature 624, 86 (2023)], which reported the autonomous discovery of 43 novel materials, as an example, we discuss problems that can arise in unsupervised materials discovery and hope that by addressing these, autonomous materials discovery can be brought closer to reality. We discuss all 43 synthetic products and point out four common shortfalls in the analysis. These errors unfortunately lead to the conclusion that no new materials have been discovered in that work. We conclude that there are two important points of improvement that require future work from the community, as follows. (i) Automated Rietveld analysis of powder x-ray diffraction data is not yet reliable. Future improvement of such, and the development of a reliable artificial-intelligence-based tool for Rietveld fitting, would be very helpful, not only for autonomous materials discovery but also for the community in general. (ii) We find that disorder in materials is often neglected in predictions. The predicted compounds investigated herein have all their elemental components located on distinct crystallographic positions but in reality, elements can share crystallographic sites, resulting in higher-symmetry space groups and—very often—known alloys or solid solutions. This error might be related to the difficulty of modeling disorder in a computationally economical way and needs to be addressed both by computational and experimental material scientists. We find that two thirds of the claimed successful materials in Szymanski et al. are likely to be known compositionally disordered versions of the predicted ordered compounds. We highlight important issues in materials discovery, computational chemistry, and autonomous interpretation of x-ray diffraction. We discuss concepts of materials discovery from an experimentalist point of view, which we hope will be helpful for the community to further advance this important new aspect of our field.},
  file = {/Users/joshgoldman/Zotero/storage/PNU9SHU7/Leeman et al. - 2024 - Challenges in High-Throughput Inorganic Materials Prediction and Autonomous Synthesis.pdf;/Users/joshgoldman/Zotero/storage/3F6M8LFZ/PRXEnergy.3.html}
}

@software{limoyoOlimoyoPytorchgeometricegnn2022,
  title = {Olimoyo/Pytorch-Geometric-Egnn},
  author = {Limoyo, Oliver},
  date = {2022-05-09T01:00:35Z},
  origdate = {2021-06-18T20:20:50Z},
  url = {https://github.com/Olimoyo/pytorch-geometric-egnn},
  urldate = {2024-05-22},
  abstract = {A minimalist implementation of E(n)-Equivariant Graph Neural Networks in PyTorch.}
}

@inproceedings{liuGraphNormalizingFlows2019,
  title = {Graph {{Normalizing Flows}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Liu, Jenny and Kumar, Aviral and Ba, Jimmy and Kiros, Jamie and Swersky, Kevin},
  date = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/1e44fdf9c44d7328fecc02d677ed704d-Abstract.html},
  urldate = {2024-05-16},
  abstract = {We introduce graph normalizing flows: a new, reversible graph neural network model for prediction and generation. On supervised tasks, graph normalizing flows perform similarly to message passing neural networks, but at a significantly reduced memory footprint, allowing them to scale to larger graphs. In the unsupervised case, we combine graph normalizing flows with a novel graph auto-encoder to create a generative model of graph structures. Our model is permutation-invariant, generating entire graphs with a single feed-forward pass, and achieves competitive results with the state-of-the art auto-regressive models, while being better suited to parallel computing architectures.},
  file = {/Users/joshgoldman/Zotero/storage/5JHGZR3T/Liu et al. - 2019 - Graph Normalizing Flows.pdf}
}

@online{luoUnderstandingDiffusionModels2022,
  title = {Understanding {{Diffusion Models}}: {{A Unified Perspective}}},
  shorttitle = {Understanding {{Diffusion Models}}},
  author = {Luo, Calvin},
  date = {2022-08-25},
  eprint = {2208.11970},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2208.11970},
  url = {http://arxiv.org/abs/2208.11970},
  urldate = {2024-05-06},
  abstract = {Diffusion models have shown incredible capabilities as generative models; indeed, they power the current state-of-the-art models on text-conditioned image generation such as Imagen and DALL-E 2. In this work we review, demystify, and unify the understanding of diffusion models across both variational and score-based perspectives. We first derive Variational Diffusion Models (VDM) as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptions enable tractable computation and scalable optimization of the ELBO. We then prove that optimizing a VDM boils down to learning a neural network to predict one of three potential objectives: the original source input from any arbitrary noisification of it, the original source noise from any arbitrarily noisified input, or the score function of a noisified input at any arbitrary noise level. We then dive deeper into what it means to learn the score function, and connect the variational perspective of a diffusion model explicitly with the Score-based Generative Modeling perspective through Tweedie's Formula. Lastly, we cover how to learn a conditional distribution using diffusion models via guidance.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/joshgoldman/Zotero/storage/PYZJA7VW/Luo - 2022 - Understanding Diffusion Models A Unified Perspective.pdf;/Users/joshgoldman/Zotero/storage/6YRL6VF9/2208.html}
}

@software{MirgroupNequip2024,
  title = {Mir-Group/Nequip},
  date = {2024-06-06T13:35:59Z},
  origdate = {2021-03-15T23:44:39Z},
  url = {https://github.com/mir-group/nequip},
  urldate = {2024-06-06},
  abstract = {NequIP is a code for building E(3)-equivariant interatomic potentials},
  organization = {MIR@Harvard},
  keywords = {atomistic-simulations,computational-chemistry,deep-learning,drug-discovery,force-fields,interatomic-potentials,machine-learning,materials-science,molecular-dynamics,pytorch}
}

@article{moghadamStructureMechanicalStabilityRelations2019,
  title = {Structure-{{Mechanical Stability Relations}} of {{Metal-Organic Frameworks}} via {{Machine Learning}}},
  author = {Moghadam, Peyman Z. and Rogge, Sven M. J. and Li, Aurelia and Chow, Chun-Man and Wieme, Jelle and Moharrami, Noushin and Aragones-Anglada, Marta and Conduit, Gareth and Gomez-Gualdron, Diego A. and Van Speybroeck, Veronique and Fairen-Jimenez, David},
  date = {2019-07-10},
  journaltitle = {Matter},
  shortjournal = {Matter},
  volume = {1},
  number = {1},
  pages = {219--234},
  issn = {2590-2385},
  doi = {10.1016/j.matt.2019.03.002},
  url = {https://www.sciencedirect.com/science/article/pii/S2590238519300062},
  urldate = {2024-05-22},
  abstract = {Assessing the mechanical stability of metal-organic frameworks (MOFs) is critical to bring these materials to any application. Here, we derive the first interactive map of the structure-mechanical landscape of MOFs by performing a multi-level computational analysis. First, we used high-throughput molecular simulations for 3,385 MOFs containing 41 distinct network topologies. Second, we developed a freely available machine-learning algorithm to automatically predict the mechanical properties of MOFs. For distinct regions of the high-throughput space, in-depth analysis based on in operando molecular dynamics simulations reveals the loss-of-crystallinity pressure within a given topology. The overarching mechanical screening approach presented here reveals the sensitivity on structural parameters such as topology, coordination characteristics and the nature of the building blocks, and paves the way for computational as well as experimental researchers to assess and design MOFs with enhanced mechanical stability to accelerate the translation of MOFs to industrial applications.},
  keywords = {artificial neural network,high-throughput screening,interactive structure-property visualization,loss of crystallinity,machine learning,MAP 3: Understanding,mechanical stability,metal-organic frameworks,MOFs in industry,molecular simulation,porous materials,topology},
  file = {/Users/joshgoldman/Zotero/storage/JK3XNJ29/Moghadam et al. - 2019 - Structure-Mechanical Stability Relations of Metal-Organic Frameworks via Machine Learning.pdf;/Users/joshgoldman/Zotero/storage/5N53TYIR/S2590238519300062.html}
}

@article{moosaviImprovingMechanicalStability2018,
  title = {Improving the {{Mechanical Stability}} of {{Metal}}–{{Organic Frameworks Using Chemical Caryatids}}},
  author = {Moosavi, Seyed Mohamad and Boyd, Peter G. and Sarkisov, Lev and Smit, Berend},
  date = {2018-07-25},
  journaltitle = {ACS Central Science},
  shortjournal = {ACS Cent. Sci.},
  volume = {4},
  number = {7},
  pages = {832--839},
  publisher = {American Chemical Society},
  issn = {2374-7943},
  doi = {10.1021/acscentsci.8b00157},
  url = {https://doi.org/10.1021/acscentsci.8b00157},
  urldate = {2024-05-18},
  abstract = {Metal–organic frameworks (MOFs) have emerged as versatile materials for applications ranging from gas separation and storage, catalysis, and sensing. The attractive feature of MOFs is that, by changing the ligand and/or metal, they can be chemically tuned to perform optimally for a given application. In most, if not all, of these applications one also needs a material that has a sufficient mechanical stability, but our understanding of how changes in the chemical structure influence mechanical stability is limited. In this work, we rationalize how the mechanical properties of MOFs are related to framework bonding topology and ligand structure. We illustrate that the functional groups on the organic ligands can either enhance the mechanical stability through formation of a secondary network of nonbonded interactions or soften the material by destabilizing the bonded network of a MOF. In addition, we show that synergistic effect of the bonding network of the material and the secondary network is required to achieve optimal mechanical stability of a MOF. The developed molecular insights in this work can be used for systematic improvement of the mechanical stability of the materials by careful selection of the functional groups.},
  file = {/Users/joshgoldman/Zotero/storage/69KB2LT3/SI.pdf;/Users/joshgoldman/Zotero/storage/Z6L6NT66/Moosavi et al. - 2018 - Improving the Mechanical Stability of Metal–Organic Frameworks Using Chemical Caryatids.pdf}
}

@article{moosaviRoleMachineLearning2020,
  title = {The {{Role}} of {{Machine Learning}} in the {{Understanding}} and {{Design}} of {{Materials}}},
  author = {Moosavi, Seyed Mohamad and Jablonka, Kevin Maik and Smit, Berend},
  date = {2020-12-02},
  journaltitle = {Journal of the American Chemical Society},
  shortjournal = {J. Am. Chem. Soc.},
  volume = {142},
  number = {48},
  pages = {20273--20287},
  publisher = {American Chemical Society},
  issn = {0002-7863},
  doi = {10.1021/jacs.0c09105},
  url = {https://doi.org/10.1021/jacs.0c09105},
  urldate = {2024-05-07},
  abstract = {Developing algorithmic approaches for the rational design and discovery of materials can enable us to systematically find novel materials, which can have huge technological and social impact. However, such rational design requires a holistic perspective over the full multistage design process, which involves exploring immense materials spaces, their properties, and process design and engineering as well as a techno-economic assessment. The complexity of exploring all of these options using conventional scientific approaches seems intractable. Instead, novel tools from the field of machine learning can potentially solve some of our challenges on the way to rational materials design. Here we review some of the chief advancements of these methods and their applications in rational materials design, followed by a discussion on some of the main challenges and opportunities we currently face together with our perspective on the future of rational materials design and discovery.},
  file = {/Users/joshgoldman/Zotero/storage/BWW6RGMC/Moosavi et al. - 2020 - The Role of Machine Learning in the Understanding and Design of Materials.pdf}
}

@article{moosaviUnderstandingDiversityMetalorganic2020,
  title = {Understanding the Diversity of the Metal-Organic Framework Ecosystem},
  author = {Moosavi, Seyed Mohamad and Nandy, Aditya and Jablonka, Kevin Maik and Ongari, Daniele and Janet, Jon Paul and Boyd, Peter G. and Lee, Yongjin and Smit, Berend and Kulik, Heather J.},
  date = {2020-08-13},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {4068},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-17755-8},
  url = {https://www.nature.com/articles/s41467-020-17755-8},
  urldate = {2024-05-09},
  abstract = {Millions of distinct metal-organic frameworks (MOFs) can be made by combining metal nodes and organic linkers. At present, over 90,000 MOFs have been synthesized and over 500,000 predicted. This raises the question whether a new experimental or predicted structure adds new information. For MOF~chemists, the chemical design space is a combination of pore geometry, metal nodes, organic linkers, and functional groups, but at present we do not have a formalism to quantify optimal coverage of chemical design space. In this work, we develop a machine learning method to quantify similarities of MOFs to analyse their chemical diversity. This diversity analysis identifies biases in the databases, and we show that such bias can lead to incorrect conclusions. The developed formalism in this study provides a simple and practical guideline to see whether new structures will have the potential for new insights, or constitute a relatively small variation of existing structures.},
  langid = {english},
  keywords = {Chemistry,Materials for energy and catalysis,Metal–organic frameworks,Theory and computation},
  file = {/Users/joshgoldman/Zotero/storage/2X93FURI/Moosavi et al. - 2020 - Understanding the diversity of the metal-organic framework ecosystem.pdf}
}

@article{okeeffeFrameworksExtendedSolids2000,
  title = {Frameworks for {{Extended Solids}}: {{Geometrical Design Principles}}},
  shorttitle = {Frameworks for {{Extended Solids}}},
  author = {O'Keeffe, M. and Eddaoudi, M. and Li, Hailian and Reineke, T. and Yaghi, O. M.},
  date = {2000-06-01},
  journaltitle = {Journal of Solid State Chemistry},
  shortjournal = {Journal of Solid State Chemistry},
  volume = {152},
  number = {1},
  pages = {3--20},
  issn = {0022-4596},
  doi = {10.1006/jssc.2000.8723},
  url = {https://www.sciencedirect.com/science/article/pii/S0022459600987231},
  urldate = {2024-05-13},
  abstract = {The basic geometries for three-dimensional low-connectivity nets are described. Examples of open framework solids with these topologies are adduced for illustration. Attention is drawn to methods of producing open frameworks by decoration and expansion of simple nets.},
  file = {/Users/joshgoldman/Zotero/storage/9BRRGC29/O'Keeffe et al. - 2000 - Frameworks for Extended Solids Geometrical Design Principles.pdf;/Users/joshgoldman/Zotero/storage/RKX2SAGW/S0022459600987231.html}
}

@article{okeeffeReticularChemistryStructure2008,
  title = {The {{Reticular Chemistry Structure Resource}} ({{RCSR}}) {{Database}} of, and {{Symbols}} for, {{Crystal Nets}}},
  author = {O’Keeffe, Michael and Peskov, Maxim A. and Ramsden, Stuart J. and Yaghi, Omar M.},
  date = {2008-12-16},
  journaltitle = {Accounts of Chemical Research},
  shortjournal = {Acc. Chem. Res.},
  volume = {41},
  number = {12},
  pages = {1782--1789},
  publisher = {American Chemical Society},
  issn = {0001-4842},
  doi = {10.1021/ar800124u},
  url = {https://doi.org/10.1021/ar800124u},
  urldate = {2024-05-10},
  abstract = {During the past decade, interest has grown tremendously in the design and synthesis of crystalline materials constructed from molecular clusters linked by extended groups of atoms. Most notable are metal−organic frameworks (MOFs), in which polyatomic inorganic metal-containing clusters are joined by polytopic linkers. (Although these materials are sometimes referred to as coordination polymers, we prefer to differentiate them, because MOFs are based on strong linkages that yield robust frameworks.) The realization that MOFs could be designed and synthesized in a rational way from molecular building blocks led to the emergence of a discipline that we call reticular chemistry. MOFs can be represented as a special kind of graph called a periodic net. Such descriptions date back to the earliest crystallographic studies but have become much more common recently because thousands of new structures and hundreds of underlying nets have been reported. In the simplest cases (e.g., the structure of diamond), the atoms in the crystal become the vertices of the net, and bonds are the links (edges) that connect them. In the case of MOFs, polyatomic groups act as the vertices and edges of the net. Because of the explosive growth in this area, a need has arisen for a universal system of nomenclature, classification, identification, and retrieval of these topological structures. We have developed a system of symbols for the identification of three periodic nets of interest, and this system is now in wide use. In this Account, we explain the underlying methodology of assigning symbols and describe the Reticular Chemistry Structure Resource (RCSR), in which about 1600 such nets are collected and illustrated in a database that can be searched by symbol, name, keywords, and attributes. The resource also contains searchable data for polyhedra and layers. The database entries come from systematic enumerations or from known chemical compounds or both. In the latter case, references to occurrences are provided. We describe some crystallographic, topological, and other attributes of nets and explain how they are reported in the database. We also describe how the database can be used as a tool for the design and structural analysis of new materials. Associated with each net is a natural tiling, which is a natural partition of space into space-filling tiles. The database allows export of data that can be used to analyze and illustrate such tilings.},
  file = {/Users/joshgoldman/Zotero/storage/GHNJ3KEW/O’Keeffe et al. - 2008 - The Reticular Chemistry Structure Resource (RCSR) Database of, and Symbols for, Crystal Nets.pdf}
}

@article{ortizAnisotropicElasticProperties2012,
  title = {Anisotropic {{Elastic Properties}} of {{Flexible Metal-Organic Frameworks}}: {{How Soft}} Are {{Soft Porous Crystals}}?},
  shorttitle = {Anisotropic {{Elastic Properties}} of {{Flexible Metal-Organic Frameworks}}},
  author = {Ortiz, Aurélie U. and Boutin, Anne and Fuchs, Alain H. and Coudert, François-Xavier},
  date = {2012-11-07},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {109},
  number = {19},
  eprint = {1209.6378},
  eprinttype = {arxiv},
  eprintclass = {cond-mat, physics:physics},
  pages = {195502},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.109.195502},
  url = {http://arxiv.org/abs/1209.6378},
  urldate = {2024-05-21},
  abstract = {We performed ab initio calculations of the elastic constants of five flexible metal-organic frameworks: MIL-53(Al), MIL-53(Ga), MIL-47 and the square and lozenge structures of DMOF-1. Tensorial analysis of the elastic constants reveal a highly anisotropic elastic behavior, some deformation directions exhibiting very low Young's modulus and shear modulus. This anisotropy can reach a 400:1 ratio between the most rigid and weakest directions, in stark contrast with the case of non-flexible MOFs such as MOF-5 and ZIF-8. In addition, we show that flexible MOFs can display extremely large negative linear compressibility (NLC). These results uncover the microscopic roots of stimuli-induced structural transitions in flexible MOFs, by linking the local elastic behavior of the material and its multistability.},
  keywords = {Condensed Matter - Materials Science,Physics - Chemical Physics},
  file = {/Users/joshgoldman/Zotero/storage/2VXEPTFC/Ortiz et al. - 2012 - Anisotropic Elastic Properties of Flexible Metal-Organic Frameworks How Soft are Soft Porous Crysta.pdf;/Users/joshgoldman/Zotero/storage/62RARA8W/1209.html}
}

@article{parkInverseDesignPorous2024a,
  title = {Inverse Design of Porous Materials: A Diffusion Model Approach},
  shorttitle = {Inverse Design of Porous Materials},
  author = {Park, Junkil and Singh~Gill, Aseem Partap and Mohamad~Moosavi, Seyed and Kim, Jihan},
  date = {2024},
  journaltitle = {Journal of Materials Chemistry A},
  volume = {12},
  number = {11},
  pages = {6507--6514},
  publisher = {Royal Society of Chemistry},
  doi = {10.1039/D3TA06274K},
  url = {https://pubs.rsc.org/en/content/articlelanding/2024/ta/d3ta06274k},
  urldate = {2024-05-10},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/QK4JDZX6/Park et al. - 2024 - Inverse design of porous materials a diffusion model approach.pdf}
}

@article{ramakrishnanBigDataMeets2015,
  title = {Big {{Data Meets Quantum Chemistry Approximations}}: {{The Δ-Machine Learning Approach}}},
  shorttitle = {Big {{Data Meets Quantum Chemistry Approximations}}},
  author = {Ramakrishnan, Raghunathan and Dral, Pavlo O. and Rupp, Matthias and family=Lilienfeld, given=O. Anatole, prefix=von, useprefix=true},
  date = {2015-05-12},
  journaltitle = {Journal of Chemical Theory and Computation},
  shortjournal = {J. Chem. Theory Comput.},
  volume = {11},
  number = {5},
  pages = {2087--2096},
  publisher = {American Chemical Society},
  issn = {1549-9618},
  doi = {10.1021/acs.jctc.5b00099},
  url = {https://doi.org/10.1021/acs.jctc.5b00099},
  urldate = {2024-05-09},
  abstract = {Chemically accurate and comprehensive studies of the virtual space of all possible molecules are severely limited by the computational cost of quantum chemistry. We introduce a composite strategy that adds machine learning corrections to computationally inexpensive approximate legacy quantum methods. After training, highly accurate predictions of enthalpies, free energies, entropies, and electron correlation energies are possible, for significantly larger molecular sets than used for training. For thermochemical properties of up to 16k isomers of C7H10O2 we present numerical evidence that chemical accuracy can be reached. We also predict electron correlation energy in post Hartree–Fock methods, at the computational cost of Hartree–Fock, and we establish a qualitative relationship between molecular entropy and electron correlation. The transferability of our approach is demonstrated, using semiempirical quantum chemistry and machine learning models trained on 1 and 10\% of 134k organic molecules, to reproduce enthalpies of all remaining molecules at density functional theory level of accuracy.},
  file = {/Users/joshgoldman/Zotero/storage/YWGAQ6F9/Ramakrishnan et al. - 2015 - Big Data Meets Quantum Chemistry Approximations The Δ-Machine Learning Approach.pdf}
}

@article{renInvertibleCrystallographicRepresentation2022,
  title = {An Invertible Crystallographic Representation for General Inverse Design of Inorganic Crystals with Targeted Properties},
  author = {Ren, Zekun and Tian, Siyu Isaac Parker and Noh, Juhwan and Oviedo, Felipe and Xing, Guangzong and Li, Jiali and Liang, Qiaohao and Zhu, Ruiming and Aberle, Armin G. and Sun, Shijing and Wang, Xiaonan and Liu, Yi and Li, Qianxiao and Jayavelu, Senthilnath and Hippalgaonkar, Kedar and Jung, Yousung and Buonassisi, Tonio},
  date = {2022-01},
  journaltitle = {Matter},
  shortjournal = {Matter},
  volume = {5},
  number = {1},
  eprint = {2005.07609},
  eprinttype = {arxiv},
  eprintclass = {cond-mat, physics:physics},
  pages = {314--335},
  issn = {25902385},
  doi = {10.1016/j.matt.2021.11.032},
  url = {http://arxiv.org/abs/2005.07609},
  urldate = {2024-05-09},
  abstract = {Realizing general inverse design could greatly accelerate the discovery of new materials with user-defined properties. However, state-of-the-art generative models tend to be limited to a specific composition or crystal structure. Herein, we present a framework capable of general inverse design (not limited to a given set of elements or crystal structures), featuring a generalized invertible representation that encodes crystals in both real and reciprocal space, and a property-structured latent space from a variational autoencoder (VAE). In three design cases, the framework generates 142 new crystals with user-defined formation energies, bandgap, thermoelectric (TE) power factor, and combinations thereof. These generated crystals, absent in the training database, are validated by first-principles calculations. The success rates (number of first-principles-validated target-satisfying crystals/number of designed crystals) ranges between 7.1\% and 38.9\%. These results represent a significant step toward property-driven general inverse design using generative models, although practical challenges remain when coupled with experimental synthesis.},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Materials Science,Physics - Computational Physics},
  file = {/Users/joshgoldman/Zotero/storage/RFIGLER4/Ren et al. - 2022 - An invertible crystallographic representation for general inverse design of inorganic crystals with.pdf;/Users/joshgoldman/Zotero/storage/JU9R26W5/2005.html}
}

@article{roggeReliablyModelingMechanical2018,
  title = {Reliably {{Modeling}} the {{Mechanical Stability}} of {{Rigid}} and {{Flexible Metal}}–{{Organic Frameworks}}},
  author = {Rogge, Sven M. J. and Waroquier, Michel and Van Speybroeck, Veronique},
  date = {2018-01-16},
  journaltitle = {Accounts of Chemical Research},
  shortjournal = {Acc. Chem. Res.},
  volume = {51},
  number = {1},
  pages = {138--148},
  publisher = {American Chemical Society},
  issn = {0001-4842},
  doi = {10.1021/acs.accounts.7b00404},
  url = {https://doi.org/10.1021/acs.accounts.7b00404},
  urldate = {2024-05-21},
  abstract = {ConspectusOver the past two decades, metal–organic frameworks (MOFs) have matured from interesting academic peculiarities toward a continuously expanding class of hybrid, nanoporous materials tuned for targeted technological applications such as gas storage and heterogeneous catalysis. These oft-times crystalline materials, composed of inorganic moieties interconnected by organic ligands, can be endowed with desired structural and chemical features by judiciously functionalizing or substituting these building blocks. As a result of this reticular synthesis, MOF research is situated at the intriguing intersection between chemistry and physics, and the building block approach could pave the way toward the construction of an almost infinite number of possible crystalline structures, provided that they exhibit stability under the desired operational conditions. However, this enormous potential is largely untapped to date, as MOFs have not yet found a major breakthrough in technological applications. One of the remaining challenges for this scale-up is the densification of MOF powders, which is generally achieved by subjecting the material to a pressurization step. However, application of an external pressure may substantially alter the chemical and physical properties of the material. A reliable theoretical guidance that can presynthetically identify the most stable materials could help overcome this technological challenge.In this Account, we describe the recent research the progress on computational characterization of the mechanical stability of MOFs. So far, three complementary approaches have been proposed, focusing on different aspects of mechanical stability: (i) the Born stability criteria, (ii) the anisotropy in mechanical moduli such as the Young and shear moduli, and (iii) the pressure-versus-volume equations of state. As these three methods are grounded in distinct computational approaches, it is expected that their accuracy and efficiency will vary. To date, however, it is unclear which set of properties are suited and reliable for a given application, as a comprehensive comparison for a broad variety of MOFs is absent, impeding the widespread use of these theoretical frameworks.Herein, we fill this gap by critically assessing the performance of the three computational models on a broad set of MOFs that are representative for current applications. These materials encompass the mechanically rigid UiO-66(Zr) and MOF-5(Zn) as well as the flexible MIL-47(V) and MIL-53(Al), which undergo pressure-induced phase transitions. It is observed that the Born stability criteria and pressure-versus-volume equations of state give complementary insight into the macroscopic and microscopic origins of instability, respectively. However, interpretation of the Born stability criteria becomes increasingly difficult when less symmetric materials are considered. Moreover, pressure fluctuations during the simulations hamper their accuracy for flexible materials. In contrast, the pressure-versus-volume equations of state are determined in a thermodynamic ensemble specifically targeted to mitigate the effects of these instantaneous fluctuations, yielding more accurate results. The critical Account presented here paves the way toward a solid computational framework for an extensive presynthetic screening of MOFs to select those that are mechanically stable and can be postsynthetically densified before their use in targeted applications.},
  file = {/Users/joshgoldman/Zotero/storage/FIVNTI4P/Rogge et al. - 2018 - Reliably Modeling the Mechanical Stability of Rigid and Flexible Metal–Organic Frameworks.pdf}
}

@article{sanchez-lengelingGentleIntroductionGraph2021a,
  title = {A {{Gentle Introduction}} to {{Graph Neural Networks}}},
  author = {Sanchez-Lengeling, Benjamin and Reif, Emily and Pearce, Adam and Wiltschko, Alexander B.},
  date = {2021-09-02},
  journaltitle = {Distill},
  shortjournal = {Distill},
  volume = {6},
  number = {9},
  pages = {e33},
  issn = {2476-0757},
  doi = {10.23915/distill.00033},
  url = {https://distill.pub/2021/gnn-intro},
  urldate = {2024-05-07},
  abstract = {What components are needed for building learning algorithms that leverage the structure and properties of graphs?},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/YJTSHWFD/gnn-intro.html}
}

@inproceedings{satorrasEquivariantGraphNeural2021,
  title = {E(n) {{Equivariant Graph Neural Networks}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Satorras, Vı́ctor Garcia and Hoogeboom, Emiel and Welling, Max},
  date = {2021-07-01},
  pages = {9323--9332},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/satorras21a.html},
  urldate = {2024-05-06},
  abstract = {This paper introduces a new model to learn graph neural networks equivariant to rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. In addition, whereas existing methods are limited to equivariance on 3 dimensional spaces, our model is easily scaled to higher-dimensional spaces. We demonstrate the effectiveness of our method on dynamical systems modelling, representation learning in graph autoencoders and predicting molecular properties.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/KD8EDPDD/Satorras et al. - 2021 - E(n) Equivariant Graph Neural Networks.pdf;/Users/joshgoldman/Zotero/storage/X6L2PFH2/Satorras et al. - 2021 - E(n) Equivariant Graph Neural Networks.pdf}
}

@article{seifridAutonomousChemicalExperiments2022,
  title = {Autonomous {{Chemical Experiments}}: {{Challenges}} and {{Perspectives}} on {{Establishing}} a {{Self-Driving Lab}}},
  shorttitle = {Autonomous {{Chemical Experiments}}},
  author = {Seifrid, Martin and Pollice, Robert and Aguilar-Granda, Andrés and Morgan Chan, Zamyla and Hotta, Kazuhiro and Ser, Cher Tian and Vestfrid, Jenya and Wu, Tony C. and Aspuru-Guzik, Alán},
  date = {2022-09-06},
  journaltitle = {Accounts of Chemical Research},
  shortjournal = {Acc. Chem. Res.},
  volume = {55},
  number = {17},
  pages = {2454--2466},
  publisher = {American Chemical Society},
  issn = {0001-4842},
  doi = {10.1021/acs.accounts.2c00220},
  url = {https://doi.org/10.1021/acs.accounts.2c00220},
  urldate = {2024-05-29},
  abstract = {ConspectusWe must accelerate the pace at which we make technological advancements to address climate change and disease risks worldwide. This swifter pace of discovery requires faster research and development cycles enabled by better integration between hypothesis generation, design, experimentation, and data analysis. Typical research cycles take months to years. However, data-driven automated laboratories, or self-driving laboratories, can significantly accelerate molecular and materials discovery. Recently, substantial advancements have been made in the areas of machine learning and optimization algorithms that have allowed researchers to extract valuable knowledge from multidimensional data sets. Machine learning models can be trained on large data sets from the literature or databases, but their performance can often be hampered by a lack of negative results or metadata. In contrast, data generated by self-driving laboratories can be information-rich, containing precise details of the experimental conditions and metadata. Consequently, much larger amounts of high-quality data are gathered in self-driving laboratories. When placed in open repositories, this data can be used by the research community to reproduce experiments, for more in-depth analysis, or as the basis for further investigation. Accordingly, high-quality open data sets will increase the accessibility and reproducibility of science, which is sorely needed.In this Account, we describe our efforts to build a self-driving lab for the development of a new class of materials: organic semiconductor lasers (OSLs). Since they have only recently been demonstrated, little is known about the molecular and material design rules for thin-film, electrically-pumped OSL devices as compared to other technologies such as organic light-emitting diodes or organic photovoltaics. To realize high-performing OSL materials, we are developing a flexible system for automated synthesis via iterative Suzuki–Miyaura cross-coupling reactions. This automated synthesis platform is directly coupled to the analysis and purification capabilities. Subsequently, the molecules of interest can be transferred to an optical characterization setup. We are currently limited to optical measurements of the OSL molecules in solution. However, material properties are ultimately most important in the solid state (e.g., as a thin-film device). To that end and for a different scientific goal, we are developing a self-driving lab for inorganic thin-film materials focused on the oxygen evolution reaction.While the future of self-driving laboratories is very promising, numerous challenges still need to be overcome. These challenges can be split into cognition and motor function. Generally, the cognitive challenges are related to optimization with constraints or unexpected outcomes for which general algorithmic solutions have yet to be developed. A more practical challenge that could be resolved in the near future is that of software control and integration because few instrument manufacturers design their products with self-driving laboratories in mind. Challenges in motor function are largely related to handling heterogeneous systems, such as dispensing solids or performing extractions. As a result, it is critical to understand that adapting experimental procedures that were designed for human experimenters is not as simple as transferring those same actions to an automated system, and there may be more efficient ways to achieve the same goal in an automated fashion. Accordingly, for self-driving laboratories, we need to carefully rethink the translation of manual experimental protocols.},
  file = {/Users/joshgoldman/Zotero/storage/8Y8TBDQ5/Seifrid et al. - 2022 - Autonomous Chemical Experiments Challenges and Perspectives on Establishing a Self-Driving Lab.pdf}
}

@article{silvaChemistryApplicationsMetal2022,
  title = {The {{Chemistry}} and {{Applications}} of {{Metal}}–{{Organic Frameworks}} ({{MOFs}}) as {{Industrial Enzyme Immobilization Systems}}},
  author = {Silva, Allison R. M. and Alexandre, Jeferson Y. N. H. and Souza, José E. S. and Neto, José G. Lima and family=Sousa Júnior, given=Paulo G., prefix=de, useprefix=true and Rocha, Maria V. P. and family=Santos, given=José C. S., prefix=dos, useprefix=true},
  date = {2022-07-15},
  journaltitle = {Molecules},
  shortjournal = {Molecules},
  volume = {27},
  number = {14},
  eprint = {35889401},
  eprinttype = {pmid},
  pages = {4529},
  issn = {1420-3049},
  doi = {10.3390/molecules27144529},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9320690/},
  urldate = {2024-05-07},
  abstract = {Enzymatic biocatalysis is a sustainable technology. Enzymes are versatile and highly efficient biocatalysts, and have been widely employed due to their biodegradable nature. However, because the three-dimensional structure of these enzymes is predominantly maintained by weaker non-covalent interactions, external conditions, such as temperature and pH variations, as well as the presence of chemical compounds, can modify or even neutralize their biological activity. The enablement of this category of processes is the result of the several advances in the areas of molecular biology and biotechnology achieved over the past two decades. In this scenario, metal–organic frameworks (MOFs) are highlighted as efficient supports for enzyme immobilization. They can be used to ‘house’ a specific enzyme, providing it with protection from environmental influences. This review discusses MOFs as structures; emphasizes their synthesis strategies, properties, and applications; explores the existing methods of using immobilization processes of various enzymes; and lists their possible chemical modifications and combinations with other compounds to formulate the ideal supports for a given application.},
  pmcid = {PMC9320690},
  file = {/Users/joshgoldman/Zotero/storage/5RJYM2YN/Silva et al. - 2022 - The Chemistry and Applications of Metal–Organic Frameworks (MOFs) as Industrial Enzyme Immobilizatio.pdf}
}

@software{TUMDAMLGemnet_pytorch2024,
  title = {{{TUM-DAML}}/Gemnet\_pytorch},
  date = {2024-05-08T02:01:55Z},
  origdate = {2021-10-11T07:30:36Z},
  url = {https://github.com/TUM-DAML/gemnet_pytorch},
  urldate = {2024-05-15},
  abstract = {GemNet model in PyTorch, as proposed in "GemNet: Universal Directional Graph Neural Networks for Molecules" (NeurIPS 2021)},
  organization = {Data Analytics and Machine Learning Group},
  keywords = {gnn,graph-neural-networks,paper,pytorch}
}

@article{unkeMachineLearningForce2021,
  title = {Machine {{Learning Force Fields}}},
  author = {Unke, Oliver T. and Chmiela, Stefan and Sauceda, Huziel E. and Gastegger, Michael and Poltavsky, Igor and Schütt, Kristof T. and Tkatchenko, Alexandre and Müller, Klaus-Robert},
  date = {2021-08-25},
  journaltitle = {Chemical Reviews},
  shortjournal = {Chem. Rev.},
  volume = {121},
  number = {16},
  pages = {10142--10186},
  publisher = {American Chemical Society},
  issn = {0009-2665},
  doi = {10.1021/acs.chemrev.0c01111},
  url = {https://doi.org/10.1021/acs.chemrev.0c01111},
  urldate = {2024-05-09},
  abstract = {In recent years, the use of machine learning (ML) in computational chemistry has enabled numerous advances previously out of reach due to the computational complexity of traditional electronic-structure methods. One of the most promising applications is the construction of ML-based force fields (FFs), with the aim to narrow the gap between the accuracy of ab initio methods and the efficiency of classical FFs. The key idea is to learn the statistical relation between chemical structure and potential energy without relying on a preconceived notion of fixed chemical bonds or knowledge about the relevant interactions. Such universal ML approximations are in principle only limited by the quality and quantity of the reference data used to train them. This review gives an overview of applications of ML-FFs and the chemical insights that can be obtained from them. The core concepts underlying ML-FFs are described in detail, and a step-by-step guide for constructing and testing them from scratch is given. The text concludes with a discussion of the challenges that remain to be overcome by the next generation of ML-FFs.},
  file = {/Users/joshgoldman/Zotero/storage/MMEU22EM/Unke et al. - 2021 - Machine Learning Force Fields.pdf}
}

@article{wangEnhancingGeometricRepresentations2024,
  title = {Enhancing Geometric Representations for Molecules with Equivariant Vector-Scalar Interactive Message Passing},
  author = {Wang, Yusong and Wang, Tong and Li, Shaoning and He, Xinheng and Li, Mingyu and Wang, Zun and Zheng, Nanning and Shao, Bin and Liu, Tie-Yan},
  date = {2024-01-05},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {313},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-43720-2},
  url = {https://www.nature.com/articles/s41467-023-43720-2},
  urldate = {2024-05-22},
  abstract = {Geometric deep learning has been revolutionizing the molecular modeling field. Despite the state-of-the-art neural network models are approaching ab initio accuracy for molecular property prediction, their applications, such as drug discovery and molecular dynamics (MD) simulation, have been hindered by insufficient utilization of geometric information and high computational costs. Here we propose an equivariant geometry-enhanced graph neural network called ViSNet, which elegantly extracts geometric features and efficiently models molecular structures with low computational costs. Our proposed ViSNet outperforms state-of-the-art approaches on multiple MD benchmarks, including MD17, revised MD17 and MD22, and achieves excellent chemical property prediction on QM9 and Molecule3D datasets. Furthermore, through a series of simulations and case studies, ViSNet can efficiently explore the conformational space and provide reasonable interpretability to map geometric representations to molecular structures.},
  langid = {english},
  keywords = {Chemical biology,Computational biology and bioinformatics,Computational models,Molecular modelling,Protein structure predictions},
  file = {/Users/joshgoldman/Zotero/storage/VFYFRDLL/Wang et al. - 2024 - Enhancing geometric representations for molecules with equivariant vector-scalar interactive message.pdf}
}

@article{wangEvaluatingSelfSupervisedLearning2023,
  title = {Evaluating {{Self-Supervised Learning}} for {{Molecular Graph Embeddings}}},
  author = {Wang, Hanchen and Kaddour, Jean and Liu, Shengchao and Tang, Jian and Lasenby, Joan and Liu, Qi},
  date = {2023-12-15},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {68028--68060},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/d6dc15cc2442a40904e704d624d1fbe8-Abstract-Datasets_and_Benchmarks.html},
  urldate = {2024-06-07},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/D3S4CUVR/Wang et al. - 2023 - Evaluating Self-Supervised Learning for Molecular Graph Embeddings.pdf}
}

@online{wengAutoencoderBetaVAE2018a,
  title = {From {{Autoencoder}} to {{Beta-VAE}}},
  author = {Weng, Lilian},
  date = {2018-08-12T00:00:00+00:00},
  url = {https://lilianweng.github.io/posts/2018-08-12-vae/},
  urldate = {2024-05-06},
  abstract = {[Updated on 2019-07-18: add a section on VQ-VAE \& VQ-VAE-2.] [Updated on 2019-07-26: add a section on TD-VAE.] Autocoder is invented to reconstruct high-dimensional data using a neural network model with a narrow bottleneck layer in the middle (oops, this is probably not true for Variational Autoencoder, and we will investigate it in details in later sections). A nice byproduct is dimension reduction: the bottleneck layer captures a compressed latent encoding.},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/6TEJTQNB/2018-08-12-vae.html}
}

@online{wengGANWGAN2017a,
  title = {From {{GAN}} to {{WGAN}}},
  author = {Weng, Lilian},
  date = {2017-08-20T00:00:00+00:00},
  url = {https://lilianweng.github.io/posts/2017-08-20-gan/},
  urldate = {2024-05-06},
  abstract = {[Updated on 2018-09-30: thanks to Yoonju, we have this post translated in Korean!] [Updated on 2019-04-18: this post is also available on arXiv.] Generative adversarial network (GAN) has shown great results in many generative tasks to replicate the real-world rich content such as images, human language, and music. It is inspired by game theory: two models, a generator and a critic, are competing with each other while making each other stronger at the same time.},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/5NCZD2EG/2017-08-20-gan.html}
}

@online{wengWhatAreDiffusion2021a,
  title = {What Are {{Diffusion Models}}?},
  author = {Weng, Lilian},
  date = {2021-07-11T00:00:00+00:00},
  url = {https://lilianweng.github.io/posts/2021-07-11-diffusion-models/},
  urldate = {2024-05-06},
  abstract = {[Updated on 2021-09-19: Highly recommend this blog post on score-based generative modeling by Yang Song (author of several key papers in the references)]. [Updated on 2022-08-27: Added classifier-free guidance, GLIDE, unCLIP and Imagen. [Updated on 2022-08-31: Added latent diffusion model. [Updated on 2024-04-13: Added progressive distillation, consistency models, and the Model Architecture section. So far, I’ve written about three types of generative models, GAN, VAE, and Flow-based models. They have shown great success in generating high-quality samples, but each has some limitations of its own.},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/Q779JFHA/2021-07-11-diffusion-models.html}
}

@article{whiteDeepLearningMolecules2021,
  title = {Deep {{Learning}} for {{Molecules}} and {{Materials}}},
  author = {White, Andrew D.},
  date = {2021},
  journaltitle = {Living Journal of Computational Molecular Science},
  volume = {3},
  number = {1},
  pages = {1499--1499},
  issn = {2575-6524},
  doi = {10.33011/livecoms.3.1.1499},
  url = {https://livecomsjournal.org/index.php/livecoms/article/view/v3i1e1499},
  urldate = {2024-05-06},
  abstract = {Deep learning is becoming a standard tool in chemistry and materials science. Although there are learning materials available for deep learning, none cover the applications in chemistry and materials science or the peculiarities of working with molecules. The textbook described here provides a systematic and applied introduction to the latest research in deep learning in chemistry and materials science. It covers the math fundamentals, the requisite machine learning, the common neural network architectures used today, and the details necessary to be a practitioner of deep learning. The textbook is a living document and will be updated as the rapidly changing deep learning field evolves.},
  issue = {1},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/MCWMF8VG/White - 2021 - Deep Learning for Molecules and Materials.pdf}
}

@online{xieCrystalDiffusionVariational2022a,
  title = {Crystal {{Diffusion Variational Autoencoder}} for {{Periodic Material Generation}}},
  author = {Xie, Tian and Fu, Xiang and Ganea, Octavian-Eugen and Barzilay, Regina and Jaakkola, Tommi},
  date = {2022-03-14},
  eprint = {2110.06197},
  eprinttype = {arxiv},
  eprintclass = {cond-mat, physics:physics},
  doi = {10.48550/arXiv.2110.06197},
  url = {http://arxiv.org/abs/2110.06197},
  urldate = {2024-05-08},
  abstract = {Generating the periodic structure of stable materials is a long-standing challenge for the material design community. This task is difficult because stable materials only exist in a low-dimensional subspace of all possible periodic arrangements of atoms: 1) the coordinates must lie in the local energy minimum defined by quantum mechanics, and 2) global stability also requires the structure to follow the complex, yet specific bonding preferences between different atom types. Existing methods fail to incorporate these factors and often lack proper invariances. We propose a Crystal Diffusion Variational Autoencoder (CDVAE) that captures the physical inductive bias of material stability. By learning from the data distribution of stable materials, the decoder generates materials in a diffusion process that moves atomic coordinates towards a lower energy state and updates atom types to satisfy bonding preferences between neighbors. Our model also explicitly encodes interactions across periodic boundaries and respects permutation, translation, rotation, and periodic invariances. We significantly outperform past methods in three tasks: 1) reconstructing the input structure, 2) generating valid, diverse, and realistic materials, and 3) generating materials that optimize a specific property. We also provide several standard datasets and evaluation metrics for the broader machine learning community.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Materials Science,Physics - Computational Physics},
  file = {/Users/joshgoldman/Zotero/storage/QDVB3ZP4/Xie et al. - 2022 - Crystal Diffusion Variational Autoencoder for Periodic Material Generation.pdf;/Users/joshgoldman/Zotero/storage/UAQNZBQD/2110.html}
}

@article{xieCrystalGraphConvolutional2018,
  title = {Crystal {{Graph Convolutional Neural Networks}} for an {{Accurate}} and {{Interpretable Prediction}} of {{Material Properties}}},
  author = {Xie, Tian and Grossman, Jeffrey C.},
  date = {2018-04-06},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {120},
  number = {14},
  pages = {145301},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.120.145301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.120.145301},
  urldate = {2024-05-08},
  abstract = {The use of machine learning methods for accelerating the design of crystalline materials usually requires manually constructed feature vectors or complex transformation of atom coordinates to input the crystal structure, which either constrains the model to certain crystal types or makes it difficult to provide chemical insights. Here, we develop a crystal graph convolutional neural networks framework to directly learn material properties from the connection of atoms in the crystal, providing a universal and interpretable representation of crystalline materials. Our method provides a highly accurate prediction of density functional theory calculated properties for eight different properties of crystals with various structure types and compositions after being trained with 104 data points. Further, our framework is interpretable because one can extract the contributions from local chemical environments to global properties. Using an example of perovskites, we show how this information can be utilized to discover empirical rules for materials design.},
  file = {/Users/joshgoldman/Zotero/storage/GRBNVDN9/SM.pdf;/Users/joshgoldman/Zotero/storage/ZXLEMFLJ/Xie and Grossman - 2018 - Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material.pdf;/Users/joshgoldman/Zotero/storage/D72CQ5DU/PhysRevLett.120.html}
}

@inproceedings{xuSelfsupervisedGraphlevelRepresentation2021,
  title = {Self-Supervised {{Graph-level Representation Learning}} with {{Local}} and {{Global Structure}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Xu, Minghao and Wang, Hang and Ni, Bingbing and Guo, Hongyu and Tang, Jian},
  date = {2021-07-01},
  pages = {11548--11558},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/xu21g.html},
  urldate = {2024-06-07},
  abstract = {This paper studies unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks such as molecule properties prediction in drug and material discovery. Existing methods mainly focus on preserving the local similarity structure between different graph instances but fail to discover the global semantic structure of the entire data set. In this paper, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local similarities, GraphLoG introduces the hierarchical prototypes to capture the global semantic clusters. An efficient online expectation-maximization (EM) algorithm is further developed for learning the model. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark data sets demonstrate the effectiveness of the proposed approach.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/88DBGS6M/Xu et al. - 2021 - Self-supervised Graph-level Representation Learning with Local and Global Structure.pdf;/Users/joshgoldman/Zotero/storage/JK4APA9V/supp.pdf}
}

@article{yangDiffusionModelsComprehensive2023,
  title = {Diffusion {{Models}}: {{A Comprehensive Survey}} of {{Methods}} and {{Applications}}},
  shorttitle = {Diffusion {{Models}}},
  author = {Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
  date = {2023-11-09},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {56},
  number = {4},
  pages = {105:1--105:39},
  issn = {0360-0300},
  doi = {10.1145/3626235},
  url = {https://dl.acm.org/doi/10.1145/3626235},
  urldate = {2024-05-06},
  abstract = {Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language processing, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy},
  keywords = {diffusion models,Generative models,score-based generative models,stochastic differential equations},
  file = {/Users/joshgoldman/Zotero/storage/979NV7GY/Yang et al. - 2023 - Diffusion Models A Comprehensive Survey of Methods and Applications.pdf}
}

@article{yangDirectionalDiffusionModels2023,
  title = {Directional Diffusion Models for Graph Representation Learning},
  author = {Yang, Run and Yang, Yuling and Zhou, Fan and Sun, Qiang},
  date = {2023-12-15},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {32720--32731},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/6751ee6546b31ceb7d4ee12276b9f4d9-Abstract-Conference.html},
  urldate = {2024-06-07},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/EK8Q334T/Yang et al. - 2023 - Directional diffusion models for graph representation learning.pdf}
}

@article{yanPeriodicGraphTransformers2022,
  title = {Periodic {{Graph Transformers}} for {{Crystal Material Property Prediction}}},
  author = {Yan, Keqiang and Liu, Yi and Lin, Yuchao and Ji, Shuiwang},
  date = {2022-12-06},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {15066--15080},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/6145c70a4a4bf353a31ac5496a72a72d-Abstract-Conference.html},
  urldate = {2024-06-07},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/Z4FZ5ILB/Yan et al. - 2022 - Periodic Graph Transformers for Crystal Material Property Prediction.pdf}
}

@inproceedings{yanSpaceGroupSymmetry2024,
  title = {A {{Space Group Symmetry Informed Network}} for {{O}}(3) {{Equivariant Crystal Tensor Prediction}}},
  author = {Yan, Keqiang and Saxton, Alexandra and Qian, Xiaofeng and Qian, Xiaoning and Ji, Shuiwang},
  date = {2024-06-06},
  url = {https://openreview.net/forum?id=BOFjRnJ9mX},
  urldate = {2024-06-11},
  abstract = {We consider the prediction of general tensor properties of crystalline materials, including dielectric, piezoelectric, and elastic tensors. A key challenge here is how to make the predictions satisfy the unique tensor equivariance to both O(3) and crystal space groups. To this end, we propose a General Materials Tensor Network (GMTNet), which is carefully designed to satisfy the required symmetries. To evaluate our method, we curate a dataset and establish evaluation metrics that are tailored to the intricacies of crystal tensor predictions. Experimental results show that our GMTNet not only achieves promising performance on crystal tensors of various orders but also generates predictions fully consistent with the intrinsic crystal symmetries. Our code is publicly available as part of the AIRS library (https://github.com/divelab/AIRS).},
  eventtitle = {Forty-First {{International Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/IFSX5RSY/Yan et al. - 2024 - A Space Group Symmetry Informed Network for O(3) Equivariant Crystal Tensor Prediction.pdf}
}

@article{yaoInverseDesignNanoporous2021,
  title = {Inverse Design of Nanoporous Crystalline Reticular Materials with Deep Generative Models},
  author = {Yao, Zhenpeng and Sánchez-Lengeling, Benjamín and Bobbitt, N. Scott and Bucior, Benjamin J. and Kumar, Sai Govind Hari and Collins, Sean P. and Burns, Thomas and Woo, Tom K. and Farha, Omar K. and Snurr, Randall Q. and Aspuru-Guzik, Alán},
  date = {2021-01},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {3},
  number = {1},
  pages = {76--86},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-00271-1},
  url = {https://www.nature.com/articles/s42256-020-00271-1},
  urldate = {2024-05-08},
  abstract = {Reticular frameworks are crystalline porous materials that form via the self-assembly of molecular building blocks in different topologies, with many having desirable properties for gas storage, separation, catalysis, biomedical applications and so on. The notable variety of building blocks makes reticular chemistry both promising and challenging for prospective materials design. Here we propose an automated nanoporous materials discovery platform powered by a supramolecular variational autoencoder for the generative design of reticular materials. We demonstrate the automated design process with a class of metal–organic framework (MOF) structures and the goal of separating carbon dioxide from natural gas or flue gas. Our model shows high fidelity in capturing MOF structural features. We show that the autoencoder has a promising optimization capability when jointly trained with multiple top adsorbent candidates identified for superior gas separation. MOFs discovered here are strongly competitive against some of the best-performing MOFs/zeolites ever reported.},
  langid = {english},
  keywords = {Cheminformatics,Metal–organic frameworks,Method development,Renewable energy,Sustainability},
  file = {/Users/joshgoldman/Zotero/storage/845VC86S/Yao et al. - 2021 - Inverse design of nanoporous crystalline reticular materials with deep generative models.pdf}
}

@online{zeniMatterGenGenerativeModel2024a,
  title = {{{MatterGen}}: A Generative Model for Inorganic Materials Design},
  shorttitle = {{{MatterGen}}},
  author = {Zeni, Claudio and Pinsler, Robert and Zügner, Daniel and Fowler, Andrew and Horton, Matthew and Fu, Xiang and Shysheya, Sasha and Crabbé, Jonathan and Sun, Lixin and Smith, Jake and Nguyen, Bichlien and Schulz, Hannes and Lewis, Sarah and Huang, Chin-Wei and Lu, Ziheng and Zhou, Yichi and Yang, Han and Hao, Hongxia and Li, Jielan and Tomioka, Ryota and Xie, Tian},
  date = {2024-01-29},
  eprint = {2312.03687},
  eprinttype = {arxiv},
  eprintclass = {cond-mat},
  doi = {10.48550/arXiv.2312.03687},
  url = {http://arxiv.org/abs/2312.03687},
  urldate = {2024-05-08},
  abstract = {The design of functional materials with desired properties is essential in driving technological advances in areas like energy storage, catalysis, and carbon capture. Generative models provide a new paradigm for materials design by directly generating entirely novel materials given desired property constraints. Despite recent progress, current generative models have low success rate in proposing stable crystals, or can only satisfy a very limited set of property constraints. Here, we present MatterGen, a model that generates stable, diverse inorganic materials across the periodic table and can further be fine-tuned to steer the generation towards a broad range of property constraints. To enable this, we introduce a new diffusion-based generative process that produces crystalline structures by gradually refining atom types, coordinates, and the periodic lattice. We further introduce adapter modules to enable fine-tuning towards any given property constraints with a labeled dataset. Compared to prior generative models, structures produced by MatterGen are more than twice as likely to be novel and stable, and more than 15 times closer to the local energy minimum. After fine-tuning, MatterGen successfully generates stable, novel materials with desired chemistry, symmetry, as well as mechanical, electronic and magnetic properties. Finally, we demonstrate multi-property materials design capabilities by proposing structures that have both high magnetic density and a chemical composition with low supply-chain risk. We believe that the quality of generated materials and the breadth of MatterGen's capabilities represent a major advancement towards creating a universal generative model for materials design.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Condensed Matter - Materials Science},
  file = {/Users/joshgoldman/Zotero/storage/M293HVIF/Zeni et al. - 2024 - MatterGen a generative model for inorganic materials design.pdf;/Users/joshgoldman/Zotero/storage/SYPF8C9M/2312.html}
}

@inproceedings{zhaoPersistenceEnhancedGraph2020,
  title = {Persistence {{Enhanced Graph Neural Network}}},
  booktitle = {Proceedings of the {{Twenty Third International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Zhao, Qi and Ye, Ze and Chen, Chao and Wang, Yusu},
  date = {2020-06-03},
  pages = {2896--2906},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v108/zhao20d.html},
  urldate = {2024-06-10},
  abstract = {Local structural information can increase the adaptability of graph convolutional networks to large graphs with heterogeneous topology. Existing methods only use relatively simplistic topological information, such as node degrees.We present a novel approach leveraging advanced topological information, i.e., persistent homology, which measures the information flow efficiency at different parts of the graph. To fully exploit such structural information in real world graphs, we propose a new network architecture which learns to use persistent homology information to reweight messages passed between graph nodes during convolution. For node classification tasks, our network outperforms existing ones on a broad spectrum of graph benchmarks.},
  eventtitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  langid = {english},
  file = {/Users/joshgoldman/Zotero/storage/6NFY83CA/Zhao et al. - 2020 - Persistence Enhanced Graph Neural Network.pdf;/Users/joshgoldman/Zotero/storage/UD4VRZZN/Zhao et al. - 2020 - Persistence Enhanced Graph Neural Network.pdf}
}
